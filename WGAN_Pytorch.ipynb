{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Training of Wasserstein GANs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "to_img= T.Compose([T.ToPILImage()])\n",
    "to_tensor = T.Compose([T.ToTensor()])\n",
    "load_norm = T.Compose([T.ToTensor(),T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.n_epoch = 200\n",
    "        self.batch_size = 64\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.latent_dim = 64\n",
    "        self.img_size = 28\n",
    "        self.channels = 1\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        self.sample_interval = 50\n",
    "        self.lambda_gp = 10\n",
    "        self.show_freq = 50\n",
    "        self.model_path = './Model/'\n",
    "        self.img_path = './Image/'  \n",
    "        \n",
    "opt = Parser()\n",
    "\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "def show_img(model,input):\n",
    "    \n",
    "    show_fn = T.Compose([T.ToPILImage()])\n",
    "    plt.imshow(show_fn(model(input)[0]))\n",
    "    \n",
    "def count_params(model):\n",
    "    \n",
    "    param_count = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    print('Number of parameters: ',param_count)\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1)\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    out_shape = torch.ones(real_samples.shape[0], 1)\n",
    "    gradients = torch.autograd.grad(outputs=d_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=out_shape, create_graph=True, retain_graph=True,\n",
    "                              only_inputs=True)[0]\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "# If we make it in a class, we need to load the data everytime\n",
    "# class WGAN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(WGAN, self).__init__()\n",
    "#         self.g = Generator()\n",
    "#         self.d = Discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Classes\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        \n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.Tensor(num_features).uniform_()) # num_featurs, depth\n",
    "            self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = [-1] + [1] * (x.dim() - 1)\n",
    "        mean = x.view(x.size(0), -1).mean(1).view(shape)\n",
    "        std = x.view(x.size(0), -1).std(1).view(shape)\n",
    "        y = (x - mean) / (std + self.eps)\n",
    "        if self.affine:\n",
    "            a_shape = [1, -1] + [1] * (x.dim() - 2)\n",
    "            y = self.gamma.view(a_shape) * y + self.beta.view(a_shape)\n",
    "        return y\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, k=5 , s=1 , p=0 ,d=1 ,normalize=True, deconv=False):\n",
    "            # Contain \"Linear -> Layernorm -> LeakyReLU\"\n",
    "            if deconv:\n",
    "                layers= nn.ModuleList([nn.ConvTranspose2d(in_feat,out_feat, k, s, p, dilation = d  )])\n",
    "            else:   \n",
    "                layers = nn.ModuleList([nn.Conv2d(in_feat, out_feat, k, s, p, d)])\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_feat))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(1, 64,5,2,2), \n",
    "            *block(64,128,3,1,1),\n",
    "            *block(128,256,3,2,1),\n",
    "            *block(256,256,3,1,2,2),\n",
    "            *block(256,256,3,1,8,8),\n",
    "            *block(256,128,4,2,1,deconv=True),\n",
    "            *block(128,64,3,1,0),\n",
    "            nn.Conv2d(64,1,3,1,0),\n",
    "            nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, z):\n",
    "        self.img = self.model(z)\n",
    "        return self.img\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "          \n",
    "        def block(in_feat, out_feat, k=5 , s=1 , p=0 ,d=1 ,normalize=True, deconv=False):\n",
    "            # Contain \"Linear -> Layernorm -> LeakyReLU\"\n",
    "            if deconv:\n",
    "                layers= nn.ModuleList([nn.ConvTranspose2d(in_feat,out_feat, k, s, p, dilation = d  )])\n",
    "            else:   \n",
    "                layers = nn.ModuleList([nn.Conv2d(in_feat, out_feat, k, s, p, d)])\n",
    "            if normalize:\n",
    "                layers.append(LayerNorm(out_feat))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(1,64,5,2,1),\n",
    "            *block(64,128,5,2,1),\n",
    "            *block(128,256,5,2,1),\n",
    "            nn.Conv2d(256,1,2,1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity.view(-1,1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.sample_interval = 200\n",
    "opt.batch_size = 64\n",
    "opt.show_freq = 50\n",
    "opt.n_epoch = 200\n",
    "\n",
    "if not os.path.exists(opt.model_path):\n",
    "    os.makedirs(opt.model_path)\n",
    "if not os.path.exists(opt.img_path):\n",
    "    os.makedirs(opt.img_path)\n",
    "    \n",
    "dataloader = torch.utils.data.DataLoader(datasets.MNIST('./data/mnist',\n",
    "                                                        train=True, download=True,\n",
    "                                                        transform=load_norm),\n",
    "                                         batch_size= opt.batch_size, shuffle=True)    \n",
    "    \n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "optim_G = torch.optim.Adam(G.parameters(),lr=opt.lr)\n",
    "optim_D = torch.optim.Adam(D.parameters(),lr=opt.lr)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "while epoch < opt.n_epoch:\n",
    "    for i,(img,_) in enumerate(dataloader):\n",
    "\n",
    "        z = torch.randn(img.shape[0],opt.channels,opt.latent_dim,opt.latent_dim) # import noise\n",
    "\n",
    "        optim_D.zero_grad()\n",
    "\n",
    "        fake_img = G(z).detach()\n",
    "\n",
    "        real_validity = D(img)\n",
    "        fake_validity = D(fake_img)\n",
    "\n",
    "        gradient_penalty = compute_gradient_penalty(D, img, fake_img)\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + opt.lambda_gp * gradient_penalty\n",
    "        d_loss.backward()\n",
    "        optim_D.step()\n",
    "        if i % opt.show_freq == 0 and i != 0:\n",
    "                    plt.figure()\n",
    "                    plt.imshow(to_img(fake_img[0]))\n",
    "                    plt.show()\n",
    "        print (\"Step [%d] | Discriminator Loss: [%.4f]\" % (i, d_loss.item()))\n",
    "\n",
    "        if i % opt.n_critic == 0 and i != 0:\n",
    "\n",
    "            optim_G.zero_grad()\n",
    "\n",
    "            fake_img = G(z)\n",
    "            fake_validity = D(fake_img)\n",
    "\n",
    "            g_loss = - torch.mean(fake_validity)\n",
    "            g_loss.backward()\n",
    "\n",
    "            optim_G.step()\n",
    "\n",
    "            print (\"Step [%d] | Generator Loss: [%.4f]\" % (i, g_loss.item()))\n",
    "\n",
    "        if i % opt.sample_interval==0 and i != 0 :\n",
    "            D_path = os.path.join(opt.model_path, \"WGAN_D_Epoch\"+str(epoch)+\"Step\"+str(i)+\".pt\")\n",
    "            torch.save(D, D_path)\n",
    "            G_path = os.path.join(opt.model_path, \"WGAN_G_Epoch\"+str(epoch)+\"Step\"+str(i)+\".pt\")\n",
    "            torch.save(G, G_path)\n",
    "            img_path = os.path.join(opt.img_path, \"WGAN_img_Epoch\"+str(epoch)+\"Step\"+str(i)+\".png\")\n",
    "            save_image(fake_img[:25],img_path, nrow=5, normalize=True,range=(-1,1))\n",
    "            print('Model & Image saved..')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
